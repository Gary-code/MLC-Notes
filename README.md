# æœºå™¨å­¦ä¹ ç¼–è¯‘ MLC

> è®²è€…: Tianqi Chen

* [è¯¾ç¨‹ä¸»é¡µ](https://mlc.ai/summer22-zh/)

* [ç¬”è®°](https://mlc.ai/zh/chapter_introduction/index.html)

## 01 æœºå™¨å­¦ä¹ ç¼–è¯‘æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ç¼–è¯‘

è¿‡å»æ˜¯é€šç”¨å¤„ç†å™¨ï¼Œé€šç”¨è½¯ä»¶ï¼š

![image-20220705225015332](https://s2.loli.net/2022/07/05/RKyZduBoScjaWVg.png)

AIæ—¶ä»£ï¼Œæœºå™¨å­¦ä¹ ç¼–è¯‘å½’æ ¹ç»“åº•å°±æ˜¯==**éƒ¨ç½²é—®é¢˜**==

![image-20220705225243270](https://s2.loli.net/2022/07/05/d2XJa8SvN5lARBb.png)



**ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ç¼–è¯‘**

æœºå™¨å­¦ä¹ ç¼–è¯‘ (machine learning compilation, MLC) æ˜¯æŒ‡ï¼Œå°†æœºå™¨å­¦ä¹ ç®—æ³•ä»å¼€å‘é˜¶æ®µï¼Œé€šè¿‡å˜æ¢å’Œä¼˜åŒ–ç®—æ³•ï¼Œä½¿å…¶å˜æˆéƒ¨ç½²çŠ¶æ€ã€‚

* **å¼€å‘å½¢å¼** æ˜¯æŒ‡æˆ‘ä»¬åœ¨å¼€å‘æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ä½¿ç”¨çš„å½¢å¼ã€‚å…¸å‹çš„å¼€å‘å½¢å¼åŒ…æ‹¬ç”¨ PyTorchã€TensorFlow æˆ– JAX ç­‰é€šç”¨æ¡†æ¶ç¼–å†™çš„æ¨¡å‹æè¿°ï¼Œä»¥åŠä¸ä¹‹ç›¸å…³çš„æƒé‡ã€‚

* **éƒ¨ç½²å½¢å¼** æ˜¯æŒ‡æ‰§è¡Œæœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºæ‰€éœ€çš„å½¢å¼ã€‚å®ƒé€šå¸¸æ¶‰åŠæœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¯ä¸ªæ­¥éª¤çš„æ”¯æ’‘ä»£ç ã€ç®¡ç†èµ„æºï¼ˆä¾‹å¦‚å†…å­˜ï¼‰çš„æ§åˆ¶å™¨ï¼Œä»¥åŠä¸åº”ç”¨ç¨‹åºå¼€å‘ç¯å¢ƒçš„æ¥å£ï¼ˆä¾‹å¦‚ç”¨äº android åº”ç”¨ç¨‹åºçš„ java APIï¼‰ã€‚

  ![](https://mlc.ai/zh/_images/dev-deploy-form.png)



**æœºå™¨å­¦ä¹ ç¼–è¯‘çš„ç›®æ ‡**

**é›†æˆä¸æœ€å°åŒ–ä¾èµ–** éƒ¨ç½²è¿‡ç¨‹é€šå¸¸æ¶‰åŠé›†æˆ (Integration)ï¼Œå³å°†å¿…è¦çš„å…ƒç´ ç»„åˆåœ¨ä¸€èµ·ä»¥ç”¨äºéƒ¨ç½²åº”ç”¨ç¨‹åºã€‚ ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³å¯ç”¨ä¸€ä¸ªå®‰å“ç›¸æœºåº”ç”¨ç¨‹åºæ¥æ£€æµ‹çŒ«ï¼Œæˆ‘ä»¬å°†éœ€è¦å›¾åƒåˆ†ç±»æ¨¡å‹çš„==å¿…è¦ä»£ç ==ï¼Œä½†ä¸éœ€è¦æ¨¡å‹æ— å…³çš„å…¶ä»–éƒ¨åˆ†ï¼ˆä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¸éœ€è¦åŒ…æ‹¬ç”¨äº NLP åº”ç”¨ç¨‹åºçš„embedding tableï¼‰ã€‚ä»£ç é›†æˆã€æœ€å°åŒ–ä¾èµ–é¡¹çš„èƒ½åŠ›èƒ½å¤Ÿå‡å°åº”ç”¨çš„å¤§å°ï¼Œå¹¶ä¸”å¯ä»¥ä½¿åº”ç”¨ç¨‹åºéƒ¨ç½²åˆ°çš„æ›´å¤šçš„ç¯å¢ƒã€‚ï¼ˆè‡ªå·±çš„ä»£ç +ç¡¬ä»¶å‚å•†æä¾›çš„ä»£ç é›†æˆï¼‰

**åˆ©ç”¨ç¡¬ä»¶åŠ é€Ÿ** æ¯ä¸ªéƒ¨ç½²ç¯å¢ƒéƒ½æœ‰è‡ªå·±çš„ä¸€å¥—åŸç”ŸåŠ é€ŸæŠ€æœ¯ï¼Œå¹¶ä¸”å…¶ä¸­è®¸å¤šæ˜¯ä¸“é—¨ä¸ºæœºå™¨å­¦ä¹ å¼€å‘çš„ã€‚æœºå™¨å­¦ä¹ ç¼–è¯‘çš„ä¸€ä¸ªç›®æ ‡å°±æ˜¯æ˜¯åˆ©ç”¨ç¡¬ä»¶æœ¬èº«çš„ç‰¹æ€§è¿›è¡ŒåŠ é€Ÿã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡æ„å»ºè°ƒç”¨åŸç”ŸåŠ é€Ÿåº“çš„éƒ¨ç½²ä»£ç æˆ–ç”Ÿæˆåˆ©ç”¨åŸç”ŸæŒ‡ä»¤ï¼ˆå¦‚ Nvidiaçš„TensorCoreï¼‰çš„ä»£ç æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚

**é€šç”¨ä¼˜åŒ–** æœ‰è®¸å¤šç­‰æ•ˆçš„æ–¹æ³•å¯ä»¥è¿è¡Œç›¸åŒçš„æ¨¡å‹æ‰§è¡Œã€‚ MLC çš„é€šç”¨ä¼˜åŒ–å½¢å¼æ˜¯ä¸åŒå½¢å¼çš„ä¼˜åŒ–ï¼Œä»¥**æœ€å°åŒ–å†…å­˜**ä½¿ç”¨æˆ–**å¹¶è¡Œæ‰§è¡Œ**æé«˜æ‰§è¡Œæ•ˆç‡çš„æ–¹å¼è½¬æ¢æ¨¡å‹æ‰§è¡Œã€‚

### 1.2 æœºå™¨å­¦ä¹ ç¼–è¯‘çš„å…³é”®è¦ç´ 

![](https://mlc.ai/zh/_images/mlc-elements.png)

**å¼ é‡ (Tensor)** æ˜¯æ‰§è¡Œä¸­æœ€é‡è¦çš„å…ƒç´ ã€‚å¼ é‡æ˜¯è¡¨ç¤ºç¥ç»ç½‘ç»œæ¨¡å‹æ‰§è¡Œçš„è¾“å…¥ã€è¾“å‡ºå’Œä¸­é—´ç»“æœçš„å¤šç»´æ•°ç»„ã€‚

**å¼ é‡å‡½æ•° (Tensor functions)** ç¥ç»ç½‘ç»œçš„â€œçŸ¥è¯†â€è¢«ç¼–ç åœ¨æƒé‡å’Œæ¥å—å¼ é‡å’Œè¾“å‡ºå¼ é‡çš„è®¡ç®—åºåˆ—ä¸­ã€‚æˆ‘ä»¬å°†è¿™äº›è®¡ç®—ç§°ä¸ºå¼ é‡å‡½æ•°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¼ é‡å‡½æ•°ä¸éœ€è¦å¯¹åº”äºç¥ç»ç½‘ç»œè®¡ç®—çš„å•ä¸ªæ­¥éª¤ã€‚éƒ¨åˆ†è®¡ç®—æˆ–æ•´ä¸ªç«¯åˆ°ç«¯è®¡ç®—ä¹Ÿå¯ä»¥çœ‹ä½œå¼ é‡å‡½æ•°ã€‚

**example:**

> å®é™…ä¸Šå°±æ˜¯åœ¨åš==**å¼ é‡å‡½æ•°çš„å˜æ¢**==
>
> * å³è¾¹ä¸€èˆ¬ä¼šç”¨ä¸€äº›åº•å±‚çš„æ±‡ç¼–ä»£ç å®ç°ï¼ï¼ˆè¿™é‡Œç”¨pythonå†™æ˜¯æ–¹ä¾¿å¤§å®¶çœ‹ï¼‰

![](https://s2.loli.net/2022/07/05/ot2a1sJ6r3czZSP.png)

* æŠ½è±¡å’Œå®ç°

![image-20220705231744668](https://s2.loli.net/2022/07/05/Bcj9z48OPiv7wMR.png)

æˆ‘ä»¬ä½¿ç”¨**æŠ½è±¡ (Abstraction)**æ¥è¡¨ç¤ºæˆ‘ä»¬ç”¨æ¥è¡¨ç¤ºç›¸åŒå¼ é‡å‡½æ•°çš„æ–¹å¼ã€‚ä¸åŒçš„æŠ½è±¡å¯èƒ½ä¼šæŒ‡å®šä¸€äº›ç»†èŠ‚ï¼Œè€Œå¿½ç•¥å…¶ä»–**å®ç°(Implementations)**ç»†èŠ‚ã€‚ä¾‹å¦‚ï¼Œ`linear_relu` å¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ªä¸åŒçš„ for å¾ªç¯æ¥å®ç°ã€‚

**æŠ½è±¡**å’Œ**å®ç°**å¯èƒ½æ˜¯æ‰€æœ‰è®¡ç®—æœºç³»ç»Ÿä¸­æœ€é‡è¦çš„å…³é”®å­—ã€‚**æŠ½è±¡æŒ‡å®šâ€œåšä»€ä¹ˆâ€ï¼Œå®ç°æä¾›â€œå¦‚ä½•â€åš**ã€‚æ²¡æœ‰å…·ä½“çš„ç•Œé™ã€‚æ ¹æ®æˆ‘ä»¬çš„çœ‹æ³•ï¼Œfor å¾ªç¯æœ¬èº«å¯ä»¥è¢«è§†ä¸ºä¸€ç§æŠ½è±¡ï¼Œå› ä¸ºå®ƒå¯ä»¥ä½¿ç”¨ python è§£é‡Šå™¨å®ç°æˆ–ç¼–è¯‘ä¸ºæœ¬åœ°æ±‡ç¼–ä»£ç ã€‚



## 02 å¼ é‡ç¨‹åºæŠ½è±¡

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¯¹å•ä¸ªå•å…ƒ**è®¡ç®—æ­¥éª¤**çš„æŠ½è±¡ä»¥åŠåœ¨æœºå™¨å­¦ä¹ ç¼–è¯‘ä¸­å¯¹è¿™äº›æŠ½è±¡çš„**å¯èƒ½çš„å˜æ¢**ã€‚

### 2.1 å…ƒå¼ é‡å‡½æ•°

æœ€åº•å±‚ä¸å¯åˆ†å‰²çš„å¼ é‡å‡½æ•°

![image-20220706142240051](https://s2.loli.net/2022/07/06/fOL9AhrB1UbvxgD.png)

### 2.2 å¼ é‡ç¨‹åºæŠ½è±¡

æˆ‘ä»¬ç§°è¿™ç±»æŠ½è±¡ä¸º ``å¼ é‡ç¨‹åºæŠ½è±¡â€™â€™ã€‚å¼ é‡ç¨‹åºæŠ½è±¡çš„ä¸€ä¸ªé‡è¦æ€§è´¨æ˜¯ï¼Œä»–ä»¬èƒ½å¤Ÿè¢«ä¸€ç³»åˆ—æœ‰æ•ˆçš„ç¨‹åºå˜æ¢æ‰€æ”¹å˜ã€‚![image-20220710210800366](https://s2.loli.net/2022/07/10/hx7lqZtsKcoQjMv.png)



### 2.3 ä»£ç ç¤ºä¾‹

[ä»£ç ](./chap2 notebooks/tensor_program_abstraction_ex.ipynb)



## 03 å¼ é‡ç¨‹åºå®è·µ

ä½¿ç”¨å¼ é‡ç¨‹åºæŠ½è±¡çš„ä¸»è¦ç›®çš„æ˜¯è¡¨ç¤ºå¾ªç¯å’Œç›¸å…³çš„ç¡¬ä»¶åŠ é€Ÿé€‰æ‹©ï¼Œå¦‚å¤šçº¿ç¨‹ã€ç‰¹æ®Šç¡¬ä»¶æŒ‡ä»¤çš„ä½¿ç”¨å’Œå†…å­˜è®¿é—®ã€‚æœºå™¨å­¦ä¹ ç¼–è¯‘æ ¸å¿ƒå°±æ˜¯å¼ é‡ç¨‹åºçš„å˜æ¢ï¼Œè¿™ä¸ªå°èŠ‚æ¥æ¢è®¨ä¸€ä¸‹**å…ƒå¼ é‡ç¨‹åºå˜æ¢**çš„ç¤ºä¾‹

ä¸ºäº†å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°è§£é‡Šï¼Œæˆ‘ä»¬ç”¨ä¸‹é¢çš„å¼ é‡è®¡ç®—ä½œä¸ºç¤ºä¾‹ã€‚å…·ä½“åœ°ï¼Œå¯¹äºä¸¤ä¸ªå¤§å°ä¸º $128 \times 128$ çš„çŸ©é˜µ A å’Œ Bï¼Œæˆ‘ä»¬è¿›è¡Œå¦‚ä¸‹ä¸¤æ­¥çš„å¼ é‡è®¡ç®—ã€‚

* $Y_{i, j} = \sum*_k A_*{i, k} \times B_{k, j}$

*  $C*_{i, j} = \mathbb{relu}(Y_*{i, j}) = \mathbb{max}(Y_{i, j}, 0)$

ä¸Šé¢çš„è®¡ç®—å¾ˆåƒåœ¨æˆ‘ä»¬ç¥ç»ç½‘ç»œä¸­ç»å¸¸çœ‹åˆ°çš„å…¸å‹çš„å…ƒå¼ é‡å‡½æ•°ï¼šä¸€ä¸ªçº¿æ€§å±‚ä¸ä¸€ä¸ª ReLU æ¿€æ´»å±‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨å¦‚ä¸‹ NumPy ä¸­çš„æ•°ç»„è®¡ç®—å®ç°è¿™ä¸¤ä¸ªæ“ä½œã€‚

```python
dtype = "float32"
a_np = np.random.rand(128, 128).astype(dtype)
b_np = np.random.rand(128, 128).astype(dtype)
# a @ b is equivalent to np.matmul(a, b)
c_mm_relu = np.maximum(a_np @ b_np, 0)
```

æˆ‘ä»¬ä½¿ç”¨pythonï¼Œè¿›è¡Œæ›´åŠ åº•å±‚çš„å®ç°ï¼Œç»™å‡ºä¸€äº›çº¦å®šï¼š

*  æˆ‘ä»¬å°†åœ¨å¿…è¦æ—¶ä½¿ç”¨å¾ªç¯è®¡ç®—ã€‚

* å¦‚æœå¯èƒ½ï¼Œæˆ‘ä»¬æ€»æ˜¯é€šè¿‡ `numpy.empty` æ˜¾å¼åœ°åˆ†é…æ•°ç»„å¹¶ä¼ é€’å®ƒä»¬ã€‚

ä¸‹é¢æ˜¯å…¶ä¸­çš„ä¸€ç§å®ç°æ–¹å¼ğŸ‘‡ï¼š

```python
def lnumpy_mm_relu(A: np.ndarray, B: np.ndarray, C: np.ndarray):
    Y = np.empty((128, 128), dtype="float32")
    for i in range(128):
        for j in range(128):
            for k in range(128):
                if k == 0:
                    Y[i, j] = 0
                Y[i, j] = Y[i, j] + A[i, k] * B[k, j]
    for i in range(128):
        for j in range(128):
            C[i, j] = max(Y[i, j], 0)
```

> ä¸‹é¢æ£€éªŒä¸€ä¸‹å®ç°æ˜¯å¦ç­‰ä»·

```python
c_np = np.empty((128, 128), dtype=dtype)
lnumpy_mm_relu(a_np, b_np, c_np)
np.testing.assert_allclose(c_mm_relu, c_np, rtol=1e-5)
```

### 3.1 TVMScriptçš„å®ç°

åœ¨çœ‹è¿‡ä½çº§ NumPy ç¤ºä¾‹åï¼Œç°åœ¨æˆ‘ä»¬å‡†å¤‡ä»‹ç» TensorIRã€‚

ä¸‹é¢çš„ä»£ç å—å±•ç¤ºäº† `mm_relu` çš„ TensorIR å®ç°ã€‚è¿™é‡Œçš„ä»£ç æ˜¯ç”¨ä¸€ç§åä¸º **TVMScript** çš„è¯­è¨€å®ç°çš„ï¼Œå®ƒæ˜¯ä¸€ç§åµŒå…¥åœ¨ Python AST ä¸­çš„ç‰¹å®šé¢†åŸŸæ–¹è¨€ã€‚

```python
@tvm.script.ir_module
class MyModule:
    @T.prim_func
    def mm_relu(A: T.Buffer[(128, 128), "float32"],
                B: T.Buffer[(128, 128), "float32"],
                C: T.Buffer[(128, 128), "float32"]):
        T.func_attr({"global_symbol": "mm_relu", "tir.noalias": True})
        Y = T.alloc_buffer((128, 128), dtype="float32")
        for i, j, k in T.grid(128, 128, 128):
            with T.block("Y"):
                vi = T.axis.spatial(128, i)
                vj = T.axis.spatial(128, j)
                vk = T.axis.reduce(128, k)
                with T.init():
                    Y[vi, vj] = T.float32(0)
                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]
        for i, j in T.grid(128, 128):
            with T.block("C"):
                vi = T.axis.spatial(128, i)
                vj = T.axis.spatial(128, j)
                C[vi, vj] = T.max(Y[vi, vj], T.float32(0))
```

* T.Buffer: åº•å±‚çš„æŠ½è±¡ï¼Œä¿å­˜ä¸€äº›æ•°æ®ï¼ˆä¸å‡½æ•°çš„å½¢å‚ä¸€ä¸€å¯¹åº”ï¼‰
* T.gridå°†æ·±å±‚çš„å¾ªç¯â™»ï¸å¯¹åº”åœ¨ä¸€èµ·

å®é™…ä¸Šè¯­å¥ä¹Ÿæ˜¯ä¸€ä¸€å¯¹åº”å…³ç³»ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://mlc.ai/zh/_images/tensor_func_and_numpy.png)

* å”¯ä¸€**ä¸åŒ**çš„åœ°æ–¹å°±åœ¨äºï¼šï¼ˆè¿™ä¸ªæ˜¯tensorIRçš„ç‰¹æ®Šæ„é€ ï¼‰

```python
with T.block("Y"):
  vi = T.axis.spatial(128, i)
  vj = T.axis.spatial(128, j)
  vk = T.axis.reduce(128, k)
```

* **å—** æ˜¯ TensorIR ä¸­çš„åŸºæœ¬è®¡ç®—å•ä½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥å—åŒ…å«æ¯”æ™®é€š NumPy ä»£ç æ›´å¤šçš„ä¿¡æ¯ã€‚ä¸€ä¸ªå—åŒ…å«ä¸€ç»„å—è½´ï¼ˆ`viã€vjã€vk`ï¼‰å’Œå›´ç»•å®ƒä»¬å®šä¹‰çš„è®¡ç®—ã€‚
* `vi,vj`æ‰€åœ¨çŸ©é˜µ`T`çš„æœ€åç»´åº¦ä¸­ï¼Œå°±æ˜¯spacial axisã€‚å¹¶ä¸”ä¸ä½ç½®æ— å…³å¯ä»¥å…ˆç®—`Y[0, 1]`ä¹Ÿå¯ä»¥å…ˆç®—`Y[5, 2]`
* `vk`æ‰€åœ¨çŸ©é˜µ`T`ä¸­ç»´åº¦æ˜¯æ¶ˆå¤±çš„ï¼Œéœ€è¦åœ¨å¾ªç¯é‡Œé¢å…¨éƒ¨éƒ½è·‘ä¸€éã€‚
* å¹¶ä¸”ç»‘å®šçš„å¾ªç¯è¿­ä»£å™¨éƒ½æ˜¯0ï½127çš„
* `"tir.noalias": True` å¯¹åº”ä¸åŒçš„å†…å­˜æŒ‡é’ˆ
* `@T.prim_func` è¡¨ç¤ºå…ƒå¼ é‡å‡½æ•°

```python
Y[0, 1] æ¡ä»¶ä¸‹è·‘kçš„å¾ªç¯[0ï½127]
```

* ä¸Šé¢çš„ä¸‰è¡Œå£°æ˜äº†å…³äºå—è½´çš„**å…³é”®æ€§è´¨**ï¼Œè¯­æ³•å¦‚ä¸‹ã€‚

```python
[block_axis] = T.axis.[axis_type]([axis_range], [mapped_value])
```

è¿™ä¸‰è¡ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š

- å®šä¹‰äº† `vi`ã€`vj`ã€`vk` åº”è¢«ç»‘å®šåˆ°çš„ä½ç½®ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸º `i`ã€`j` å’Œ `k`ï¼‰ï¼›
- å£°æ˜äº† `vi`ã€`vj`ã€`vk` çš„åŸå§‹èŒƒå›´ï¼ˆ`T.axis.spatial(128, i)` ä¸­çš„ `128`ï¼‰ï¼›
- å£°æ˜äº†å—è½´çš„å±æ€§ï¼ˆ`spatial`, `reduce`ï¼‰ã€‚

ä½†ä¸€èˆ¬ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä¼šå†™æˆï¼š

```python
vi, vj, vk = T.axis.remap("SSR", [i, j, k])
```

```python
@tvm.script.ir_module
class MyModule:
    @T.prim_func
    def mm_relu(A: T.Buffer[(128, 128), "float32"],
                B: T.Buffer[(128, 128), "float32"],
                C: T.Buffer[(128, 128), "float32"]):
        T.func_attr({"global_symbol": "mm_relu", "tir.noalias": True})
        Y = T.alloc_buffer((128, 128), dtype="float32")
        for i, j, k in T.grid(128, 128, 128):
            with T.block("Y"):
                vi, vj, vk = T.axis.remap("SSR", [i, j, k])
                with T.init():
                    Y[vi, vj] = T.float32(0)
                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]
        for i, j in T.grid(128, 128):
            with T.block("C"):
                vi = T.axis.spatial(128, i)
                vj = T.axis.spatial(128, j)
                C[vi, vj] = T.max(Y[vi, vj], T.float32(0))
```

åŒæ—¶ï¼Œ`IR Module`å½“ä¸­è¿˜å¯ä»¥åŒ…æ‹¬**å¤šä¸ªå…ƒå¼ é‡å‡½æ•°**!

### 3.2 å‡½æ•°å‚æ•°ä¸ç¼“å†²åŒº



